\begin{table}[htb]
    \centering
    \caption{Hyperparameter search space}
    \resizebox{0.95\linewidth}{!}{% 
    \begin{tabular}{lcll}
    \toprule
        \textbf{Process/Model} & \textbf{\#} & \textbf{Hyperparameter} & \textbf{Range of values} \\
        ~ & ~ & ~ & \small{(N = Number of features)}\\ \hline
        Data prep. & 1 & Window size & 2, 4, 8 seconds \\ \hline
        CNN & 1 & Number of units, Number of filters & 16, 32, 64, 128 \\ 
        ~ & 2 & Learning rate & Constant, Adaptive \\
        ~ & 3 & Kernel size, Pool size & \{3, 5, 7\}, \{2, 3\} \\ 
        ~ & 4 & Number of units in dense layer & 16, 32, 64, 128 \\ \hline
        LSTM & 1 & Number of units & 25, 50, 75, 100,150 \\ 
        ~ & 2 & Learning rate & Constant, Adaptive \\ \hline
        Neural networks & 1 & Number of units in hidden layer(s) & ($\frac{N}{4}$), ($\frac{N}{2}$), ($N$),($\frac{N}{2}$,$\frac{N}{4}$), ($N$,$\frac{N}{2}$)\\
        ~ & 2 & Learning rate & Const., Adapt. \\ 
        ~ & 3 & Alpha (L2 regularization) & 0.01, 0.001, 0.0001 \\ \hline
        Random forest & 1 & Maximum depth of tree & None, 5, 10, 15 \\ 
        ~ & 2 & Maximum features for best split & $N^2$, $\log_2N$ \\ 
        ~ & 3 & Minimum samples for a leaf node & 2, 5, 10 \\ 
        ~ & 4 & Number of estimators & 50, 100, 200, 500 \\ \hline
        Decision tree & 1 & Maximum depth of tree & None, 5, 10, 15 \\ 
        ~ & 2 & Maximum features for best split & $N^2$, $\log_2N$ \\ 
        ~ & 3 & Minimum samples for a leaf node & 2, 5, 10 \\ \bottomrule
    \end{tabular}}
    \label{hyperparameters_fatigue_chap}
\end{table}